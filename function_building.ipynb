{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/02_Data_Discovery_CMR-STAC_API.html\n",
    "\n",
    "from pystac_client import Client  \n",
    "from collections import defaultdict    \n",
    "import json\n",
    "import geopandas\n",
    "# import geoviews as gv\n",
    "from cartopy import crs\n",
    "# gv.extension('bokeh', 'matplotlib')\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find hls tiles given a point\n",
    "\n",
    "def find_hls_tiles(point=False, band=False, limit=False, collections = ['HLSL30.v2.0', 'HLSS30.v2.0'], date_range = False):\n",
    "\n",
    "    STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "\n",
    "    catalog = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        x, y = point[0], point[1]\n",
    "        # print(x,y)\n",
    "    except TypeError:\n",
    "        print(\"Point must be in the form of [lat,lon]\")\n",
    "        raise\n",
    "\n",
    "    point = geopandas.points_from_xy([x],[y])\n",
    "    point = point[0]\n",
    "\n",
    "\n",
    "\n",
    "    # JOHN - THIS IS WHERE YOU WOULD ADD IN SEARCH PARAMETERS\n",
    "    if date_range:\n",
    "\n",
    "        search = catalog.search(\n",
    "            collections=collections, intersects = point, datetime=date_range)\n",
    "    else:\n",
    "        search = catalog.search(\n",
    "            collections=collections, intersects = point)\n",
    "\n",
    "\n",
    "\n",
    "    # print(f'{search.matched()} Tiles Found...')\n",
    "\n",
    "\n",
    "    item_collection = search.get_all_items()\n",
    "\n",
    "    if limit:\n",
    "        item_collection = item_collection[:limit]\n",
    "\n",
    "    if band:\n",
    "        links = []\n",
    "        if type(band) == list:\n",
    "            for i in item_collection:\n",
    "                for b in band:\n",
    "                    link = i.assets[b].href\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "        \n",
    "        else:\n",
    "            for i in item_collection:\n",
    "                link = i.assets[band].href\n",
    "                links.append(link)\n",
    "    \n",
    "    else:\n",
    "        links =[]\n",
    "        for i in item_collection:\n",
    "            # print(i.assets)\n",
    "            for key in i.assets:\n",
    "                if key.startswith('B'):\n",
    "                    # link = i.assets[key].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')\n",
    "                    link = i.assets[key].href\n",
    "\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, find the nodes\n",
    "\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_reach_nodes(data_dir, reach_id):\n",
    "\n",
    "    all_nodes = []\n",
    "\n",
    "    files = glob.glob(os.path.join(data_dir, '*'))\n",
    "    print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "    for i in files:\n",
    "\n",
    "        rootgrp = netCDF4.Dataset(i, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "        node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "        if len(node_ids_indexes[0])!=0:\n",
    "            for y in node_ids_indexes[0]:\n",
    "                node_id = str(rootgrp.groups['nodes'].variables['node_id'][y].data.astype('U'))\n",
    "                all_nodes.append(node_id)\n",
    "\n",
    "\n",
    "\n",
    "            # all_nodes.extend(node_ids[0].tolist())\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    print(f'Found {len(set(all_nodes))} nodes...')\n",
    "    return list(set(all_nodes))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get_reach_nodes(data_dir,74270100221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, find the lat/lon points of all nodes\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "\n",
    "\n",
    "def get_reach_node_cords(data_dir, reach_id):\n",
    "\n",
    "    all_nodes = []\n",
    "\n",
    "    files = glob.glob(os.path.join(data_dir, '*'))\n",
    "    print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "    for i in files:\n",
    "\n",
    "        rootgrp = netCDF4.Dataset(i, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "        node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "        if len(node_ids_indexes[0])!=0:\n",
    "            for y in node_ids_indexes[0]:\n",
    "\n",
    "                lat = str(rootgrp.groups['nodes'].variables['x'][y].data.astype('U'))\n",
    "                lon = str(rootgrp.groups['nodes'].variables['y'][y].data.astype('U'))\n",
    "                all_nodes.append([lat,lon])\n",
    "\n",
    "\n",
    "\n",
    "            # all_nodes.extend(node_ids[0].tolist())\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    print(f'Found {len(all_nodes)} nodes...')\n",
    "    return all_nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, create download links for any hls tiles that intersect the nodes in the reach\n",
    "\n",
    "\n",
    "def find_download_links_for_reach_tiles(data_dir, reach_id):\n",
    "    node_coords = get_reach_node_cords(data_dir,reach_id)\n",
    "    all_links = []\n",
    "    for i in node_coords:\n",
    "        print(i)\n",
    "        links = find_hls_tiles(i,limit=1)\n",
    "        print(links)\n",
    "        all_links.extend(links)\n",
    "\n",
    "    return list(set(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching across 7 continents for nodes...\n",
      "Found 84 nodes...\n",
      "['-89.4447009885916', '37.4435521655434']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "reach_id = 74270100221\n",
    "\n",
    "all_links =  find_download_links_for_reach_tiles(data_dir, reach_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rasterio.env.Env at 0x7fd6782d0050>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/05_Data_Access_Direct_S3.html\n",
    "\n",
    "# need to make netrc file\n",
    "\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "import boto3\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.plot import show\n",
    "import rioxarray\n",
    "# import geoviews as gv\n",
    "# import hvplot.xarray\n",
    "# import holoviews as hv\n",
    "# gv.extension('bokeh', 'matplotlib')\n",
    "\n",
    "\n",
    "s3_cred_endpoint = 'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials'\n",
    "\n",
    "def get_temp_creds():\n",
    "    temp_creds_url = s3_cred_endpoint\n",
    "    return requests.get(temp_creds_url).json()\n",
    "\n",
    "\n",
    "temp_creds_req = get_temp_creds()\n",
    "\n",
    "\n",
    "session = boto3.Session(aws_access_key_id=temp_creds_req['accessKeyId'], \n",
    "                        aws_secret_access_key=temp_creds_req['secretAccessKey'],\n",
    "                        aws_session_token=temp_creds_req['sessionToken'],\n",
    "                        region_name='us-west-2')\n",
    "\n",
    "\n",
    "rio_env = rio.Env(AWSSession(session),\n",
    "                  GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                  GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "\n",
    "            \n",
    "rio_env.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_da = rioxarray.open_rasterio(list(all_links)[0], chuncks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/hlstutorial/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36mgetLogger\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[0;31m#---------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m     \"\"\"\n\u001b[1;32m   1930\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreating\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnecessary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'rasterio._env.log_error'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/confluence/anaconda3/envs/hlstutorial/lib/python3.7/logging/__init__.py\", line 1928, in getLogger\n",
      "    def getLogger(name=None):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = hls_da.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('/data/data/downloads/Aqusat_TSS_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2001-06-04\n",
       "1        1992-06-02\n",
       "2        2002-06-05\n",
       "3        1992-08-19\n",
       "4        1984-09-18\n",
       "            ...    \n",
       "32141    2008-08-11\n",
       "32142    2017-10-16\n",
       "32143    2013-09-27\n",
       "32144    2016-07-18\n",
       "32145    2010-10-13\n",
       "Name: date, Length: 32146, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = df['date'];dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = \"2001-06-04T00:00:00Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, date = str(df.iloc[100]['lat']), str(df.iloc[100]['long']), df.iloc[0]['date']\n",
    "i = [lat,lon]\n",
    "# i = ['-89.4447009885916', '37.4435521655434']\n",
    "# print(lat,lon,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    lat, lon, date = str(df.iloc[i]['lat']), str(df.iloc[i]['long']), df.iloc[0]['date']\n",
    "    point = [lat,lon]\n",
    "    try:\n",
    "        find_hls_tiles(point=[lat, lon], limit=1)\n",
    "        print('success')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45721/1614519674.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lat' is not defined"
     ]
    }
   ],
   "source": [
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('hlstutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ba854cefeea420105352005a7fd47290ef8212ad72b2335f23a5c2f1b863bf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
