{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/02_Data_Discovery_CMR-STAC_API.html\n",
    "\n",
    "from pystac_client import Client  \n",
    "from collections import defaultdict    \n",
    "import json\n",
    "import geopandas\n",
    "# import geoviews as gv\n",
    "from cartopy import crs\n",
    "# gv.extension('bokeh', 'matplotlib')\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find hls tiles given a point\n",
    "\n",
    "def find_hls_tiles(point=False, band=False, limit=False, collections = ['HLSL30.v2.0', 'HLSS30.v2.0']):\n",
    "\n",
    "    STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "\n",
    "    catalog = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        x, y = point[0], point[1]\n",
    "    except TypeError:\n",
    "        print(\"Point must be in the form of [lat,lon]\")\n",
    "        raise\n",
    "\n",
    "    point = geopandas.points_from_xy([x],[y])\n",
    "    point = point[0]\n",
    "\n",
    "\n",
    "\n",
    "    # JOHN - THIS IS WHERE YOU WOULD ADD IN SEARCH PARAMETERS\n",
    "    search = catalog.search(\n",
    "        collections=collections, intersects = point)\n",
    "\n",
    "\n",
    "    # print(f'{search.matched()} Tiles Found...')\n",
    "\n",
    "\n",
    "    item_collection = search.get_all_items()\n",
    "\n",
    "    if limit:\n",
    "        item_collection = item_collection[:limit]\n",
    "\n",
    "    if band:\n",
    "        links = []\n",
    "        if type(band) == list:\n",
    "            for i in item_collection:\n",
    "                for b in band:\n",
    "                    link = i.assets[b].href\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "        \n",
    "        else:\n",
    "            for i in item_collection:\n",
    "                link = i.assets[band].href\n",
    "                links.append(link)\n",
    "    \n",
    "    else:\n",
    "        links =[]\n",
    "        for i in item_collection:\n",
    "            # print(i.assets)\n",
    "            for key in i.assets:\n",
    "                if key.startswith('B'):\n",
    "                    # link = i.assets[key].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')\n",
    "                    link = i.assets[key].href\n",
    "\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, find the nodes\n",
    "\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_reach_nodes(data_dir, reach_id):\n",
    "\n",
    "    all_nodes = []\n",
    "\n",
    "    files = glob.glob(os.path.join(data_dir, '*'))\n",
    "    print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "    for i in files:\n",
    "\n",
    "        rootgrp = netCDF4.Dataset(i, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "        node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "        if len(node_ids_indexes[0])!=0:\n",
    "            for y in node_ids_indexes[0]:\n",
    "                node_id = str(rootgrp.groups['nodes'].variables['node_id'][y].data.astype('U'))\n",
    "                all_nodes.append(node_id)\n",
    "\n",
    "\n",
    "\n",
    "            # all_nodes.extend(node_ids[0].tolist())\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    print(f'Found {len(set(all_nodes))} nodes...')\n",
    "    return list(set(all_nodes))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get_reach_nodes(data_dir,74270100221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, find the lat/lon points of all nodes\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "\n",
    "\n",
    "def get_reach_node_cords(data_dir, reach_id):\n",
    "\n",
    "    all_nodes = []\n",
    "\n",
    "    files = glob.glob(os.path.join(data_dir, '*'))\n",
    "    print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "    for i in files:\n",
    "\n",
    "        rootgrp = netCDF4.Dataset(i, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "        node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "        if len(node_ids_indexes[0])!=0:\n",
    "            for y in node_ids_indexes[0]:\n",
    "\n",
    "                lat = str(rootgrp.groups['nodes'].variables['x'][y].data.astype('U'))\n",
    "                lon = str(rootgrp.groups['nodes'].variables['y'][y].data.astype('U'))\n",
    "                all_nodes.append([lat,lon])\n",
    "\n",
    "\n",
    "\n",
    "            # all_nodes.extend(node_ids[0].tolist())\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    print(f'Found {len(all_nodes)} nodes...')\n",
    "    return all_nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, create download links for any hls tiles that intersect the nodes in the reach\n",
    "\n",
    "\n",
    "def find_download_links_for_reach_tiles(data_dir, reach_id):\n",
    "    node_coords = get_reach_node_cords(data_dir,reach_id)\n",
    "    all_links = []\n",
    "    for i in node_coords:\n",
    "        links = find_hls_tiles(i,limit=1)\n",
    "        all_links.extend(links)\n",
    "\n",
    "    return list(set(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching across 7 continents for nodes...\n",
      "Found 84 nodes...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "reach_id = 74270100221\n",
    "\n",
    "all_links =  find_download_links_for_reach_tiles(data_dir, reach_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rasterio.env.Env at 0x7f699d6e0710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/05_Data_Access_Direct_S3.html\n",
    "\n",
    "# need to make netrc file\n",
    "\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "import boto3\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.plot import show\n",
    "import rioxarray\n",
    "# import geoviews as gv\n",
    "# import hvplot.xarray\n",
    "# import holoviews as hv\n",
    "# gv.extension('bokeh', 'matplotlib')\n",
    "\n",
    "\n",
    "s3_cred_endpoint = 'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials'\n",
    "\n",
    "def get_temp_creds():\n",
    "    temp_creds_url = s3_cred_endpoint\n",
    "    return requests.get(temp_creds_url).json()\n",
    "\n",
    "\n",
    "temp_creds_req = get_temp_creds()\n",
    "\n",
    "\n",
    "session = boto3.Session(aws_access_key_id=temp_creds_req['accessKeyId'], \n",
    "                        aws_secret_access_key=temp_creds_req['secretAccessKey'],\n",
    "                        aws_session_token=temp_creds_req['sessionToken'],\n",
    "                        region_name='us-west-2')\n",
    "\n",
    "\n",
    "rio_env = rio.Env(AWSSession(session),\n",
    "                  GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                  GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "\n",
    "            \n",
    "rio_env.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_da = rioxarray.open_rasterio(list(all_links)[0], chuncks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = hls_da.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-9999, -9999, -9999, ...,  2434,  2467,  2409],\n",
       "        [-9999, -9999, -9999, ...,  2405,  2466,  2363],\n",
       "        [-9999, -9999, -9999, ...,  2447,  2494,  2425],\n",
       "        ...,\n",
       "        [ 3157,  3164,  3044, ...,  2202,  1852,  1874],\n",
       "        [ 3187,  3143,  3189, ...,  2054,  1926,  2020],\n",
       "        [ 3291,  3174,  3216, ...,  2160,  2046,  2103]]], dtype=int16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in john csv and pull hls for that date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('hlstutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ba854cefeea420105352005a7fd47290ef8212ad72b2335f23a5c2f1b863bf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
