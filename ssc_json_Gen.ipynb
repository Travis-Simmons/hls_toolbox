{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/02_Data_Discovery_CMR-STAC_API.html\n",
    "\n",
    "from pystac_client import Client  \n",
    "from collections import defaultdict    \n",
    "import json\n",
    "import geopandas\n",
    "# import geoviews as gv\n",
    "from cartopy import crs\n",
    "# gv.extension('bokeh', 'matplotlib')\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find hls tiles given a point\n",
    "\n",
    "def find_hls_tiles(point=False, band=False, limit=False, collections = ['HLSL30.v2.0', 'HLSS30.v2.0'], date_range = False):\n",
    "\n",
    "    STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "\n",
    "    catalog = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        x, y = point[0], point[1]\n",
    "        # print(x,y)\n",
    "    except TypeError:\n",
    "        print(\"Point must be in the form of [lat,lon]\")\n",
    "        raise\n",
    "\n",
    "    point = geopandas.points_from_xy([x],[y])\n",
    "    point = point[0]\n",
    "\n",
    "\n",
    "\n",
    "    # JOHN - THIS IS WHERE YOU WOULD ADD IN SEARCH PARAMETERS\n",
    "    if date_range:\n",
    "\n",
    "        search = catalog.search(\n",
    "            collections=collections, intersects = point, datetime=date_range)\n",
    "    else:\n",
    "        search = catalog.search(\n",
    "            collections=collections, intersects = point)\n",
    "\n",
    "\n",
    "\n",
    "    # print(f'{search.matched()} Tiles Found...')\n",
    "\n",
    "\n",
    "    item_collection = search.get_all_items()\n",
    "\n",
    "    if limit:\n",
    "        item_collection = item_collection[:limit]\n",
    "\n",
    "    if band:\n",
    "        links = []\n",
    "        if type(band) == list:\n",
    "            for i in item_collection:\n",
    "                for b in band:\n",
    "                    link = i.assets[b].href\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "        \n",
    "        else:\n",
    "            for i in item_collection:\n",
    "                link = i.assets[band].href\n",
    "                links.append(link)\n",
    "    \n",
    "    else:\n",
    "        links =[]\n",
    "        for i in item_collection:\n",
    "            # print(i.assets)\n",
    "            for key in i.assets:\n",
    "                if key.startswith('B'):\n",
    "                    # link = i.assets[key].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')\n",
    "                    link = i.assets[key].href\n",
    "\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, find the nodes\n",
    "\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_reach_nodes(data_dir, reach_id):\n",
    "\n",
    "    all_nodes = []\n",
    "\n",
    "    files = glob.glob(os.path.join(data_dir, '*'))\n",
    "    print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "    for i in files:\n",
    "\n",
    "        rootgrp = netCDF4.Dataset(i, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "        node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "        if len(node_ids_indexes[0])!=0:\n",
    "            for y in node_ids_indexes[0]:\n",
    "                node_id = str(rootgrp.groups['nodes'].variables['node_id'][y].data.astype('U'))\n",
    "                all_nodes.append(node_id)\n",
    "\n",
    "\n",
    "\n",
    "            # all_nodes.extend(node_ids[0].tolist())\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    print(f'Found {len(set(all_nodes))} nodes...')\n",
    "    return list(set(all_nodes))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get_reach_nodes(data_dir,74270100221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, find the lat/lon points of all nodes\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = '/home/confluence/data/mnt/input/sword'\n",
    "\n",
    "\n",
    "def get_reach_node_cords(data_dir, reach_id):\n",
    "\n",
    "    all_nodes = []\n",
    "\n",
    "    files = glob.glob(os.path.join(data_dir, '*'))\n",
    "    print(f'Searching across {len(files)} continents for nodes...')\n",
    "\n",
    "    for i in files:\n",
    "\n",
    "        rootgrp = netCDF4.Dataset(i, \"r\", format=\"NETCDF4\")\n",
    "\n",
    "        node_ids_indexes = np.where(rootgrp.groups['nodes'].variables['reach_id'][:].data.astype('U') == str(reach_id))\n",
    "\n",
    "        if len(node_ids_indexes[0])!=0:\n",
    "            for y in node_ids_indexes[0]:\n",
    "\n",
    "                lat = str(rootgrp.groups['nodes'].variables['x'][y].data.astype('U'))\n",
    "                lon = str(rootgrp.groups['nodes'].variables['y'][y].data.astype('U'))\n",
    "                all_nodes.append([lat,lon])\n",
    "\n",
    "\n",
    "\n",
    "            # all_nodes.extend(node_ids[0].tolist())\n",
    "\n",
    "        rootgrp.close()\n",
    "\n",
    "    print(f'Found {len(all_nodes)} nodes...')\n",
    "    return all_nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a reach ID, create download links for any hls tiles that intersect the nodes in the reach\n",
    "\n",
    "\n",
    "def find_download_links_for_reach_tiles(data_dir, reach_id):\n",
    "    node_coords = get_reach_node_cords(data_dir,reach_id)\n",
    "    all_links = []\n",
    "    for i in node_coords:\n",
    "        print(i)\n",
    "        links = find_hls_tiles(i,limit=1)\n",
    "        print(links)\n",
    "        all_links.extend(links)\n",
    "\n",
    "    return list(set(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/05_Data_Access_Direct_S3.html\n",
    "\n",
    "# need to make netrc file\n",
    "\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "import boto3\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.plot import show\n",
    "import rioxarray\n",
    "# import geoviews as gv\n",
    "# import hvplot.xarray\n",
    "# import holoviews as hv\n",
    "# gv.extension('bokeh', 'matplotlib')\n",
    "\n",
    "\n",
    "s3_cred_endpoint = 'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials'\n",
    "\n",
    "def get_temp_creds():\n",
    "    temp_creds_url = s3_cred_endpoint\n",
    "    return requests.get(temp_creds_url).json()\n",
    "\n",
    "\n",
    "temp_creds_req = get_temp_creds()\n",
    "\n",
    "\n",
    "session = boto3.Session(aws_access_key_id=temp_creds_req['accessKeyId'], \n",
    "                        aws_secret_access_key=temp_creds_req['secretAccessKey'],\n",
    "                        aws_session_token=temp_creds_req['sessionToken'],\n",
    "                        region_name='us-west-2')\n",
    "\n",
    "\n",
    "rio_env = rio.Env(AWSSession(session),\n",
    "                  GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                  GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "\n",
    "            \n",
    "# rio_env.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hls_da = rioxarray.open_rasterio(list(all_links)[0], chuncks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test = hls_da.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('/data/data/downloads/Aqusat_TSS_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2001-06-04\n",
       "1        1992-06-02\n",
       "2        2002-06-05\n",
       "3        1992-08-19\n",
       "4        1984-09-18\n",
       "            ...    \n",
       "32141    2008-08-11\n",
       "32142    2017-10-16\n",
       "32143    2013-09-27\n",
       "32144    2016-07-18\n",
       "32145    2010-10-13\n",
       "Name: date, Length: 32146, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = df['date'];dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = \"2001-06-04T00:00:00Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, date = str(df.iloc[100]['lat']), str(df.iloc[100]['long']), df.iloc[0]['date']\n",
    "i = [lat,lon]\n",
    "# i = ['-89.4447009885916', '37.4435521655434']\n",
    "# print(lat,lon,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssc_json_gen(aquasat_path):\n",
    "    ssc_dict = {}\n",
    "    # read in aquasat\n",
    "    # if it finds a link add entry to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    lat, lon, date = str(df.iloc[i]['lat']), str(df.iloc[i]['long']), df.iloc[0]['date']\n",
    "    try:\n",
    "        #date not working\n",
    "        links = find_hls_tiles(point=[lon, lat], date_range=date)\n",
    "        if len(links)>0:\n",
    "            print(links)\n",
    "            break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'47.529724'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('hlstutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ba854cefeea420105352005a7fd47290ef8212ad72b2335f23a5c2f1b863bf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
