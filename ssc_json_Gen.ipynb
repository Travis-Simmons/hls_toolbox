{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSC JSON GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find hls tiles given a point\n",
    "\n",
    "def find_hls_tiles(point=False, band=False, limit=False, collections = ['HLSL30.v2.0', 'HLSS30.v2.0'], date_range = False):\n",
    "\n",
    "    STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "\n",
    "    catalog = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        x, y = point[0], point[1]\n",
    "        # print(x,y)\n",
    "    except TypeError:\n",
    "        print(\"Point must be in the form of [lon,lat]\")\n",
    "        raise\n",
    "\n",
    "    point = geopandas.points_from_xy([x],[y])\n",
    "    point = point[0]\n",
    "\n",
    "\n",
    "\n",
    "    # JOHN - THIS IS WHERE YOU WOULD ADD IN SEARCH PARAMETERS\n",
    "    if date_range:\n",
    "\n",
    "        search = catalog.search(\n",
    "            collections=collections, intersects = point, datetime=date_range)\n",
    "    else:\n",
    "        search = catalog.search(\n",
    "            collections=collections, intersects = point)\n",
    "\n",
    "\n",
    "\n",
    "    # print(f'{search.matched()} Tiles Found...')\n",
    "\n",
    "\n",
    "    item_collection = search.get_all_items()\n",
    "\n",
    "    if limit:\n",
    "        item_collection = item_collection[:limit]\n",
    "\n",
    "    if band:\n",
    "        links = []\n",
    "        if type(band) == list:\n",
    "            for i in item_collection:\n",
    "                for b in band:\n",
    "                    link = i.assets[b].href\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "        \n",
    "        else:\n",
    "            for i in item_collection:\n",
    "                link = i.assets[band].href\n",
    "                links.append(link)\n",
    "    \n",
    "    else:\n",
    "        links =[]\n",
    "        for i in item_collection:\n",
    "            # print(i.assets)\n",
    "            for key in i.assets:\n",
    "                if key.startswith('B'):\n",
    "                    # link = i.assets[key].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')\n",
    "                    link = i.assets[key].href\n",
    "\n",
    "                    # print(link)\n",
    "                    links.append(link)\n",
    "\n",
    "    return links\n",
    "\n",
    "def datestdtojd (stddate):\n",
    "    fmt='%Y-%m-%d'\n",
    "    sdtdate = datetime.datetime.strptime(stddate, fmt)\n",
    "    sdtdate = sdtdate.timetuple()\n",
    "    jdate = sdtdate.tm_yday\n",
    "    return(stddate[:4]+str(jdate))\n",
    "\n",
    "def jdtodatestd (jdate):\n",
    "    fmt = '%Y%j'\n",
    "    datestd = datetime.datetime.strptime(jdate, fmt).date()\n",
    "    out = datestd.strftime( '%Y-%m-%d')\n",
    "    return out\n",
    "\n",
    "\n",
    "def ssc_json_gen(aquasat_path):\n",
    "    ssc_dict = {}\n",
    "\n",
    "    # read in aquasat\n",
    "    df = pd.read_csv(aquasat_path)\n",
    "\n",
    "    f = IntProgress(min=0, max=len(df)) # instantiate the bar\n",
    "    display(f) # display the bar\n",
    "\n",
    "    fails = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        lat, lon, date = str(df.iloc[i]['lat']), str(df.iloc[i]['long']), df.iloc[0]['date']\n",
    "        try:\n",
    "            # date = datestdtojd('2013-01-13')\n",
    "            # print(date)\n",
    "            links = find_hls_tiles(point=[lon, lat])\n",
    "            if len(links)>0:\n",
    "                date_list = []\n",
    "                for l in links:\n",
    "                    date = l.split('/')[-1].split('.')[3][:7]\n",
    "                    date_list.append(date)\n",
    "\n",
    "                date_list = [jdtodatestd(x) for x in set(date_list)]\n",
    "\n",
    "                date_list.sort(key=lambda date: datetime.datetime.strptime(date, '%Y-%m-%d'))\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                date_dict = {}\n",
    "                for z in date_list:\n",
    "                    \n",
    "                    link_list_for_date = []\n",
    "                    for y in links:\n",
    "                        date = y.split('/')[-1].split('.')[3][:7]\n",
    "                        date = jdtodatestd(date)\n",
    "                        if date == z:\n",
    "                            link_list_for_date.append(y)\n",
    "                    \n",
    "                    # build_entry\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    # fix\n",
    "                    res = sorted(link_list_for_date, key = lambda x: x.split('.')[-2][1:])\n",
    "                    # print(res)\n",
    "                    link_list_for_date = res\n",
    "                    date_dict[z] = link_list_for_date\n",
    "\n",
    "                ssc_dict[str(lon) +','+ str(lat)]  = date_dict\n",
    "                break\n",
    "                \n",
    "        except:\n",
    "            fails +=1\n",
    "        f.value += 1 # signal to increment the progress bar\n",
    "        time.sleep(.1)\n",
    "    print(f'Total fails: {fails} ')\n",
    "    print(f'Total Success: {len(df)-fails}')\n",
    "    return ssc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5bbd4c99054a20961dbf5d255c6053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=32146)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fails: 0 \n",
      "Total Success: 32146\n"
     ]
    }
   ],
   "source": [
    "# https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/02_Data_Discovery_CMR-STAC_API.html\n",
    "\n",
    "# https://rafatieppo.github.io/post/2018_12_01_juliandate/\n",
    "\n",
    "from pystac_client import Client  \n",
    "from collections import defaultdict    \n",
    "import json\n",
    "import geopandas\n",
    "from cartopy import crs\n",
    "import geopandas as gpd\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "aqua_path = '/data/data/downloads/Aqusat_TSS_v1.csv'\n",
    "\n",
    "jj = ssc_json_gen(aqua_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B01.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B01.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B02.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B02.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B03.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B03.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B04.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B04.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B05.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B05.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B06.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B06.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B07.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B07.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B08.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B09.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B09.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B10.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B10.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T15TWN.2022316T165848.v2.0/HLS.L30.T15TWN.2022316T165848.v2.0.B11.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B11.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B12.tif',\n",
       " 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSS30.020/HLS.S30.T15TWN.2022316T170539.v2.0/HLS.S30.T15TWN.2022316T170539.v2.0.B8A.tif']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj['-92.141332,47.529724']['2022-11-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing json\n",
    "json_object = json.dumps(jj, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('hlstutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ba854cefeea420105352005a7fd47290ef8212ad72b2335f23a5c2f1b863bf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
